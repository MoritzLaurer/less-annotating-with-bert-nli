## Less Annotating, More Classifying with Deep Transfer Learning
This is the project repository for the paper "Less Annotating, More Classifying â€“ Addressing the Data Scarcity Issue of Supervised Machine Learning with Deep Transfer Learning and BERT-NLI"

This repository contains the full code and data for reproducing the paper.[^1] An earlier pre-print version of the paper is available [here](https://osf.io/wqc86/) and an improved version is currently under review. The repository will be updated upon acceptance. 

We also provide an easy-to-use Google Colab notebook for testing BERT-NLI with free access to a GPU. We invite anyone to run and copy this notebook and to train their own BERT-NLI model on their own data: https://colab.research.google.com/drive/1-y7o-QRWp-OwGMe64CxQwQk2-o2jZFm3?usp=sharing 

[^1]: Note that the raw data file for the Manifesto corpus has not been uploaded, as its 400+ MB size exceed the 100 MB data limit by GitHub. 